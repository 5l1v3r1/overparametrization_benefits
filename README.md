# The Benefits of Over-parameterization at Initialization in Deep ReLU Networks
Code for the paper: The Benefits of Over-parameterization at Initialization in Deep ReLU Networks (https://arxiv.org/abs/1901.03611)

A detailed analysis of initialization for Weight normalized networks with and without residual connection has been moved to our new paper: How to Initialize your Network? Robust Initialization for WeightNorm & ResNets (https://arxiv.org/abs/1906.02341). Its code is available at https://github.com/victorcampos7/weightnorm-init.
